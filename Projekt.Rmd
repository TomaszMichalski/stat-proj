---
title: "Projekt zaliczeniowy"
author: "Tomasz Michalski, Aleksander Mikucki"
date: "17 06 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tree)
library(randomForest)
library(gbm)
```

## Wstęp

W projekcie korzystamy ze zbioru Bike Sharing Demand:\
https://www.kaggle.com/c/bike-sharing-demand/ \
Zawiera on godzinowe dane dot. wynajmu rowerów obejmujące dwa lata.\
Projekt ma na celu porównanie różnych metod statystycznych i ich jakości w przewidywaniu liczby wynajętych rowerów.

### Ładowanie danych

Podzieliliśmy kolumnę `datetime` poprzez wyeksportowanie do osobnych kolumn miesiąca, dnia i godziny.\
Usunęliśmy także kolumny `casual` i `registered`, gdyż chcemy skupić się na kolumnie `count`, która jest ich sumą.

```{r}
bike <- read.csv("data.csv", header = TRUE)
bike <- bike[bike$datetime >= "2012-01-01 00:00:00", ]
bike <- bike[, -c(10, 11)]

bike$datetime <-as.POSIXct(bike$datetime, format="%Y-%m-%d %H:%M:%S")
bike$month <- strftime(bike$datetime, '%m')
bike$month <- as.integer(bike$month)
bike$day <-  strftime(bike$datetime, '%d')
bike$day <- as.integer(bike$day)
bike$hour <- substring(bike$datetime, 12,13)
bike$hour <- as.integer(bike$hour)

bike <- bike[,-1]

set.seed(1)
n <- nrow(bike)
train <- sample(1:n, n / 2)
test <- -train
```

### Prezentacja danych

```{r}
cat("Wierszy w zbiorze: ", nrow(bike), "\n")
```

```{r}
head(bike)
```

## Regresja liniowa

### Regresja dla każdego predyktora osobno

Dopasowujemy model prostej regresji dla każdego predyktora osobno.

```{r}
simple_coef <- c()
for (predictor in names(bike)) {
  if (predictor != "count") {
    lmFitSimple <- lm(count ~ bike[, predictor], data = bike, subset = train)
    simple_coef <- append(simple_coef, lmFitSimple$coefficients[2])
    cat("########", predictor)
    print(summary(lmFitSimple))
  }
}
```

Otrzymaliśmy wysoką istotność statystyczną dla predyktorów `season`, `weather`, `temp`, `atemp`, `humidity`, `windspeed`, `month`, oraz `hour`.

### Regresja wielokrotna

Wykonujemy regresję zmiennej `count` względem wszystkich pozostałych.

```{r}
lmFit <- lm(count ~ ., data = bike, subset = train)
summary(lmFit)
```

Korzystając z `summary`, możemy zauważyć, że cechami najbardziej istotnymi statystycznie są `humidity`, `month` oraz `hour`.

## TODO

## TODO

## Drzewa decyzyjne

### Drzewa regresyjne

Konstruujemy drzewo decyzyjne dla problemu regresji `count` względem pozostałych zmiennych.

```{r}
count.tree <- tree(count ~ ., data = bike, subset = train)
summary(count.tree)
```

Przedstawienie drzewa.

```{r}
plot(count.tree)
text(count.tree)
```

Metodą zbioru walidacyjnego szacujemy błąd testowy.

```{r}
count.tree.pred <- predict(count.tree, newdata = bike[test, ])
mean((count.tree.pred - bike$count[test])^2)
```

Wyznaczamy optymalne poddrzewo metodą przycinania sterowanego złożonością.

```{r}
count.tree.cv <- cv.tree(count.tree)
plot(count.tree.cv$size, count.tree.cv$dev, type = "b")
```

W tym przypadku przycinanie drzewa nie wytworzy bardziej optymalnego drzewa.

### Bagging

Bagging dla regresji `count` względem wszystkich pozostałych zmiennych.

```{r}
count.bag <- randomForest(count ~ ., data = bike, subset = train, mtry = 6, importance = TRUE)
count.bag
```

Wyznaczenie ważności predyktorów.

```{r}
importance(count.bag)
varImpPlot(count.bag)
```

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.

```{r}
count.bag.pred <- predict(count.bag, newdata = bike[test,])
mean((count.bag.pred - bike$count[test])^2)
```

### Lasy losowe

Lasy losowe dla regresji `count` względem wszystkich pozostałych zmiennych.

```{r}
count.rf <- randomForest(count ~ ., data = bike, subset = train, importance = TRUE)
count.rf
```

Wyznaczenie ważności predyktorów.

```{r}
importance(count.rf)
varImpPlot(count.rf)
```

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.

```{r}
count.rf.pred <- predict(count.rf, newdata = bike[test,])
mean((count.rf.pred - bike$count[test])^2)
```

### Boosting

Boosting dla regresji `count` względem pozostałych zmiennych.

```{r}
count.boost <- gbm(count ~ ., data = bike[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 4)
count.boost
```

Wyznaczenie ważności predyktorów.

```{r}
summary(count.boost)
```

Oszacowanie błędu testowego dla poprzednio wyznaczonego zbioru walidacyjnego.

```{r}
count.boost.pred <- predict(count.boost, newdata = bike[test,], n.trees = 5000)
mean((count.boost.pred - bike$count[test])^2)
```

To samo dla `shrinkage = 0.01`.

```{r}
count.boost <- gbm(count ~ ., data = bike[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)
count.boost.pred <- predict(count.boost, newdata = bike[test,], n.trees = 5000)
mean((count.boost.pred - bike$count[test])^2)
```

To samo dla `interaction.depth = 1`.

```{r}
count.boost <- gbm(count ~ ., data = bike[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 1, shrinkage = 0.01)
count.boost.pred <- predict(count.boost, newdata = bike[test,], n.trees = 5000)
mean((count.boost.pred - bike$count[test])^2)
```
